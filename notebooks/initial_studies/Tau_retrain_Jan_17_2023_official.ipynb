{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-21 18:48:45.961849: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "#Import stuff\n",
    "import uproot4\n",
    "import numpy as np\n",
    "import awkward as ak\n",
    "from scipy.stats import norm\n",
    "from scipy.optimize import curve_fit\n",
    "import os\n",
    "import copy\n",
    "\n",
    "import tensorflow.keras as keras\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import Model, Sequential, load_model\n",
    "\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import optparse\n",
    "import importlib\n",
    "import pathlib\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as colors\n",
    "import mplhep as hep\n",
    "plt.style.use(hep.style.ROOT)\n",
    "\n",
    "import matplotlib.pylab as pylab\n",
    "params = {'legend.fontsize': 'medium',\n",
    "         'axes.labelsize': 'x-large',\n",
    "         'axes.titlesize':'x-large',\n",
    "         'xtick.labelsize':'medium',\n",
    "         'ytick.labelsize':'medium'}\n",
    "pylab.rcParams.update(params)\n",
    "\n",
    "#line thickness\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['lines.linewidth'] = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create training data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_training_data(dir_path):\n",
    "    \n",
    "    #Might have to change the version for other ntuple files\n",
    "    sig = uproot4.open(dir_path+\"/test_sig_v8.root\")\n",
    "    bkg = uproot4.open(dir_path+\"/test_bkg_v8.root\")\n",
    "    \n",
    "    sig_input = sig['ntuplePupSingle']['tree']['m_inputs'].array()\n",
    "    bkg_input = bkg['ntuplePupSingle']['tree']['m_inputs'].array()\n",
    "    \n",
    "    pt_sig = sig['ntuplePupSingle']['tree']['genpt1'].array()\n",
    "    deltaR_sig = sig['ntuplePupSingle']['tree']['gendr1'].array()\n",
    "    selection_sig = (pt_sig > 40) & (abs(deltaR_sig) < 0.4)\n",
    "    \n",
    "    pt_bkg = bkg['ntuplePupSingle']['tree']['pt'].array()\n",
    "    selection_bkg = pt_bkg > 20\n",
    "    \n",
    "    #Maybe better to use 2.4 for eta\n",
    "    \n",
    "    #Inputs: pt, eta, phi, particle id(one hot encoded)\n",
    "    X_sig = np.asarray(sig_input[selection_sig])\n",
    "    y_sig = np.full(X_sig.shape[0], 1)\n",
    "    \n",
    "    X_bkg = np.asarray(bkg_input[selection_bkg])\n",
    "    y_bkg = np.full(X_bkg.shape[0], 0)\n",
    "    \n",
    "    X = np.concatenate([X_sig, X_bkg])\n",
    "    y = np.concatenate([y_sig, y_bkg])\n",
    "    \n",
    "    index = np.arange(X.shape[0])\n",
    "    \n",
    "    X_train, X_test, y_train, y_test, index_train, index_test = train_test_split(X, y, index, test_size=0.2, random_state=42)\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test, index_train, index_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test, index_train, index_test = create_training_data(\"../ntuples/Jan_17_2023\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save the arrays\n",
    "np.save(\"../ntuples/Jan_17_2023/X_train.npy\", X_train)\n",
    "np.save(\"../ntuples/Jan_17_2023/X_test.npy\", X_test)\n",
    "\n",
    "np.save(\"../ntuples/Jan_17_2023/y_train.npy\", y_train)\n",
    "np.save(\"../ntuples/Jan_17_2023/y_test.npy\", y_test)\n",
    "\n",
    "np.save(\"../ntuples/Jan_17_2023/index_train.npy\", index_train)\n",
    "np.save(\"../ntuples/Jan_17_2023/index_test.npy\", index_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 25)                2025      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                260       \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 10)                110       \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 11        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,406\n",
      "Trainable params: 2,406\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-21 18:48:52.069736: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-01-21 18:48:52.075198: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(25, activation = 'relu', input_shape=X_train.shape[1:]))\n",
    "model.add(Dense(10, activation = 'relu'))\n",
    "model.add(Dense(10, activation = 'relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy',optimizer='adam', metrics=['binary_accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1647/1647 - 11s - loss: nan - binary_accuracy: 0.3812 - val_loss: nan - val_binary_accuracy: 0.2912 - 11s/epoch - 7ms/step\n",
      "Epoch 2/50\n",
      "1647/1647 - 12s - loss: nan - binary_accuracy: 0.2938 - val_loss: nan - val_binary_accuracy: 0.2912 - 12s/epoch - 8ms/step\n",
      "Epoch 3/50\n",
      "1647/1647 - 12s - loss: nan - binary_accuracy: 0.2938 - val_loss: nan - val_binary_accuracy: 0.2912 - 12s/epoch - 8ms/step\n",
      "Epoch 4/50\n",
      "1647/1647 - 12s - loss: nan - binary_accuracy: 0.2938 - val_loss: nan - val_binary_accuracy: 0.2912 - 12s/epoch - 7ms/step\n",
      "Epoch 5/50\n",
      "1647/1647 - 12s - loss: nan - binary_accuracy: 0.2938 - val_loss: nan - val_binary_accuracy: 0.2912 - 12s/epoch - 8ms/step\n",
      "Epoch 5: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fb80cf78a30>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Train the network\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', verbose=1, patience=5)\n",
    " \n",
    "model.fit(X_train, y_train,\n",
    "          epochs=50,\n",
    "          batch_size=50,\n",
    "          verbose=2,\n",
    "          validation_split=0.20,\n",
    "          callbacks=[callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save the model\n",
    "model.save('../models/L1Tau_official.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ROC curve on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "804/804 [==============================] - 3s 4ms/step\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_test)\u001b[38;5;241m.\u001b[39mravel()\n\u001b[0;32m----> 3\u001b[0m fpr, tpr, thresholds \u001b[38;5;241m=\u001b[39m \u001b[43mroc_curve\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m auc_score \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mround\u001b[39m(auc(fpr, tpr),\u001b[38;5;241m2\u001b[39m)\n",
      "File \u001b[0;32m/work/submit/dhoang/miniconda3/envs/tau_training/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:992\u001b[0m, in \u001b[0;36mroc_curve\u001b[0;34m(y_true, y_score, pos_label, sample_weight, drop_intermediate)\u001b[0m\n\u001b[1;32m    904\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mroc_curve\u001b[39m(\n\u001b[1;32m    905\u001b[0m     y_true, y_score, \u001b[38;5;241m*\u001b[39m, pos_label\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, drop_intermediate\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    906\u001b[0m ):\n\u001b[1;32m    907\u001b[0m     \u001b[38;5;124;03m\"\"\"Compute Receiver operating characteristic (ROC).\u001b[39;00m\n\u001b[1;32m    908\u001b[0m \n\u001b[1;32m    909\u001b[0m \u001b[38;5;124;03m    Note: this implementation is restricted to the binary classification task.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    990\u001b[0m \u001b[38;5;124;03m    array([1.8 , 0.8 , 0.4 , 0.35, 0.1 ])\u001b[39;00m\n\u001b[1;32m    991\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 992\u001b[0m     fps, tps, thresholds \u001b[38;5;241m=\u001b[39m \u001b[43m_binary_clf_curve\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    993\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_score\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpos_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpos_label\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\n\u001b[1;32m    994\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    996\u001b[0m     \u001b[38;5;66;03m# Attempt to drop thresholds corresponding to points in between and\u001b[39;00m\n\u001b[1;32m    997\u001b[0m     \u001b[38;5;66;03m# collinear with other points. These are always suboptimal and do not\u001b[39;00m\n\u001b[1;32m    998\u001b[0m     \u001b[38;5;66;03m# appear on a plotted ROC curve (and thus do not affect the AUC).\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1003\u001b[0m     \u001b[38;5;66;03m# but does not drop more complicated cases like fps = [1, 3, 7],\u001b[39;00m\n\u001b[1;32m   1004\u001b[0m     \u001b[38;5;66;03m# tps = [1, 2, 4]; there is no harm in keeping too many thresholds.\u001b[39;00m\n\u001b[1;32m   1005\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m drop_intermediate \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(fps) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m:\n",
      "File \u001b[0;32m/work/submit/dhoang/miniconda3/envs/tau_training/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:755\u001b[0m, in \u001b[0;36m_binary_clf_curve\u001b[0;34m(y_true, y_score, pos_label, sample_weight)\u001b[0m\n\u001b[1;32m    753\u001b[0m y_score \u001b[38;5;241m=\u001b[39m column_or_1d(y_score)\n\u001b[1;32m    754\u001b[0m assert_all_finite(y_true)\n\u001b[0;32m--> 755\u001b[0m \u001b[43massert_all_finite\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_score\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    757\u001b[0m \u001b[38;5;66;03m# Filter out zero-weighted samples, as they should not impact the result\u001b[39;00m\n\u001b[1;32m    758\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/work/submit/dhoang/miniconda3/envs/tau_training/lib/python3.8/site-packages/sklearn/utils/validation.py:190\u001b[0m, in \u001b[0;36massert_all_finite\u001b[0;34m(X, allow_nan, estimator_name, input_name)\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21massert_all_finite\u001b[39m(\n\u001b[1;32m    165\u001b[0m     X,\n\u001b[1;32m    166\u001b[0m     \u001b[38;5;241m*\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    169\u001b[0m     input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    170\u001b[0m ):\n\u001b[1;32m    171\u001b[0m     \u001b[38;5;124;03m\"\"\"Throw a ValueError if X contains NaN or infinity.\u001b[39;00m\n\u001b[1;32m    172\u001b[0m \n\u001b[1;32m    173\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    188\u001b[0m \u001b[38;5;124;03m        documentation.\u001b[39;00m\n\u001b[1;32m    189\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 190\u001b[0m     \u001b[43m_assert_all_finite\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    191\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43missparse\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    192\u001b[0m \u001b[43m        \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_nan\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    193\u001b[0m \u001b[43m        \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    194\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    195\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/work/submit/dhoang/miniconda3/envs/tau_training/lib/python3.8/site-packages/sklearn/utils/validation.py:161\u001b[0m, in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m estimator_name \u001b[38;5;129;01mand\u001b[39;00m input_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m has_nan_error:\n\u001b[1;32m    145\u001b[0m     \u001b[38;5;66;03m# Improve the error message on how to handle missing values in\u001b[39;00m\n\u001b[1;32m    146\u001b[0m     \u001b[38;5;66;03m# scikit-learn.\u001b[39;00m\n\u001b[1;32m    147\u001b[0m     msg_err \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    148\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not accept missing values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    149\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m encoded as NaN natively. For supervised learning, you might want\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    159\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m#estimators-that-handle-nan-values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    160\u001b[0m     )\n\u001b[0;32m--> 161\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg_err)\n",
      "\u001b[0;31mValueError\u001b[0m: Input contains NaN."
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test).ravel()\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred)\n",
    "\n",
    "auc_score = round(auc(fpr, tpr),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create plot for ROC\n",
    "plt.figure(1)\n",
    "\n",
    "plt.plot([0,1],[0,1],'k--')\n",
    "plt.plot(fpr, tpr, label = 'Tau NN, AUC: {}'.format(auc_score))\n",
    "\n",
    "#Establish labels and save image\n",
    "plt.xlabel('False positive rate')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_chargedIso(indir):\n",
    "    \n",
    "    sig = uproot4.open(indir+\"/test_sig_v8.root\")\n",
    "    bkg = uproot4.open(indir+\"/test_bkg_v8.root\")\n",
    "    \n",
    "    #signal\n",
    "    pt_sig = sig['ntuplePupSingle']['tree']['genpt1'].array()\n",
    "    deltaR_sig = sig['ntuplePupSingle']['tree']['gendr1'].array()\n",
    "    \n",
    "    selection_sig = (pt_sig > 20) & (abs(deltaR_sig) < 0.4)\n",
    "    \n",
    "    nn_score_sig = sig['ntuplePupSingle']['tree']['chargedIso'].array()\n",
    "    \n",
    "    selected_sig_score = np.asarray(nn_score_sig[selection_sig])\n",
    "    true_id_sig = np.full(selected_sig_score.shape, 1) #All 1s because this is the signal sample\n",
    "    \n",
    "    #background\n",
    "    pt_bkg = bkg['ntuplePupSingle']['tree']['pt'].array()\n",
    "    deltaR_bkg = bkg['ntuplePupSingle']['tree']['gendr1'].array()\n",
    "    \n",
    "    selection_bkg = pt_bkg > 20\n",
    "    nn_score_bkg = bkg['ntuplePupSingle']['tree']['chargedIso'].array()\n",
    "    \n",
    "    selected_bkg_score = np.asarray(nn_score_bkg[selection_bkg])\n",
    "    true_id_bkg = np.full(selected_bkg_score.shape, 0)\n",
    "    \n",
    "    nn_score = np.concatenate([selected_sig_score, selected_bkg_score])\n",
    "    true_id = np.concatenate([true_id_sig, true_id_bkg])\n",
    "    \n",
    "    fpr, tpr, thresholds = roc_curve(true_id, nn_score,pos_label=1)\n",
    "    auc_score = round(auc(fpr, tpr),2)\n",
    "    \n",
    "    return fpr, tpr, auc_score\n",
    "\n",
    "#Plot for charged iso aswell\n",
    "fpr_iso, tpr_iso, auc_score_iso = get_chargedIso('../ntuples/Jan_17_2023/')\n",
    "plt.figure(1)\n",
    "\n",
    "plt.plot([0,1],[0,1],'k--')\n",
    "plt.plot(fpr, tpr, label = 'Retrained Tau NN, AUC: {}'.format(auc_score))\n",
    "plt.plot(fpr_iso, tpr_iso, label = 'Old Tau NN, AUC: {}'.format(auc_score_iso))\n",
    "\n",
    "#Establish labels and save image\n",
    "plt.xlabel('False positive rate')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

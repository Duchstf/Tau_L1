{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7aacb458",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Object `curve_fit` not found.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-19 06:51:54.406659: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "#Import stuff\n",
    "import uproot4\n",
    "import numpy as np\n",
    "import awkward as ak\n",
    "from scipy.stats import norm\n",
    "from scipy.optimize import curve_fit?\n",
    "import os\n",
    "import copy\n",
    "\n",
    "import tensorflow.keras as keras\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import Model, Sequential, load_model\n",
    "\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import optparse\n",
    "import importlib\n",
    "import pathlib\n",
    "\n",
    "import hist\n",
    "from hist import Hist\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as colors\n",
    "import mplhep as hep\n",
    "plt.style.use(hep.style.ROOT)\n",
    "\n",
    "# import matplotlib.pylab as pylab\n",
    "# params = {'legend.fontsize': 'medium',\n",
    "#          'axes.labelsize': 'x-large',\n",
    "#          'axes.titlesize':'x-large',\n",
    "#          'xtick.labelsize':'medium',\n",
    "#          'ytick.labelsize':'medium'}\n",
    "# pylab.rcParams.update(params)\n",
    "\n",
    "# #line thickness\n",
    "# import matplotlib as mpl\n",
    "# mpl.rcParams['lines.linewidth'] = 5\n",
    "\n",
    "import torch\n",
    "from torch.nn.functional import binary_cross_entropy_with_logits\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from monotonenorm import direct_norm, SigmaNet, GroupSort\n",
    "\n",
    "\n",
    "monotonic = True\n",
    "LIP = 0.5  # lipschitz constant of the model\n",
    "EPOCHS = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f01a0ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_training_data(dir_path):\n",
    "    \n",
    "    #Might have to change the version for other ntuple files\n",
    "    sig = uproot4.open(dir_path+\"/test_sig_v8.root\")\n",
    "    bkg = uproot4.open(dir_path+\"/test_bkg_v8.root\")\n",
    "    \n",
    "    sig_input = sig['ntuplePupSingle']['tree']['m_inputs'].array()\n",
    "    bkg_input = bkg['ntuplePupSingle']['tree']['m_inputs'].array()\n",
    "    \n",
    "    pt_sig = sig['ntuplePupSingle']['tree']['pt'].array()\n",
    "    deltaR_sig = sig['ntuplePupSingle']['tree']['gendr1'].array()\n",
    "    selection_sig = (abs(deltaR_sig) < 0.4)\n",
    "    \n",
    "    pt_bkg = bkg['ntuplePupSingle']['tree']['pt'].array()\n",
    "    deltaR_bkg = bkg['ntuplePupSingle']['tree']['gendr1'].array()\n",
    "    selection_bkg = pt_bkg > 20\n",
    "    \n",
    "    #Maybe better to use 2.4 for eta\n",
    "    \n",
    "    #Inputs: pt, eta, phi, particle id(one hot encoded)\n",
    "    X_sig = np.asarray(sig_input[selection_sig])\n",
    "    y_sig = np.full(X_sig.shape[0], 1)\n",
    "    \n",
    "    X_bkg = np.asarray(bkg_input[selection_bkg])\n",
    "    y_bkg = np.full(X_bkg.shape[0], 0)\n",
    "    \n",
    "    X = np.concatenate([X_sig, X_bkg])\n",
    "    y = np.concatenate([y_sig, y_bkg])\n",
    "    \n",
    "    index = np.arange(X.shape[0])\n",
    "    \n",
    "    X_train, X_test, y_train, y_test, index_train, index_test = train_test_split(X, y, index, test_size=0.2, random_state=42)\n",
    "    \n",
    "    return torch.from_numpy(X_train), torch.from_numpy(X_test), torch.from_numpy(y_train), torch.from_numpy(y_test), torch.from_numpy(index_train), torch.from_numpy(index_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "48d53d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test, index_train, index_test = create_training_data(\"../ntuples/Jan_17_2023\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "58e155f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "contraint_index_part = [1] + [0]*7\n",
    "contraint_index = contraint_index_part*10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "08cd620f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(monotonic):\n",
    "    def lipschitz_norm(module):\n",
    "          return direct_norm(\n",
    "              module,  # the layer to constrain\n",
    "              \"inf\",  # |W|_1 constraint type\n",
    "              max_norm=LIP ** (1 / 3),  # norm of the layer (LIP ** (1/nlayers))\n",
    "              )\n",
    "\n",
    "    model = torch.nn.Sequential(\n",
    "      lipschitz_norm(torch.nn.Linear(80, 50)),\n",
    "      GroupSort(5),\n",
    "      lipschitz_norm(torch.nn.Linear(50, 25)),\n",
    "      GroupSort(5),\n",
    "      lipschitz_norm(torch.nn.Linear(25, 25)),\n",
    "      GroupSort(5),\n",
    "      lipschitz_norm(torch.nn.Linear(25, 10)),\n",
    "      GroupSort(5),\n",
    "      lipschitz_norm(torch.nn.Linear(10, 1)),\n",
    "    )\n",
    "\n",
    "    if monotonic:\n",
    "        model = SigmaNet(\n",
    "          model,\n",
    "          sigma=LIP,\n",
    "          monotone_constraints=contraint_index,\n",
    "          # 0: don't constrain feature monotonicity,\n",
    "          # 1: monotonically increasing,\n",
    "          # -1: monotonically decreasing\n",
    "          # for each feature individually\n",
    "        )\n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "df00666b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_model(monotonic)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7a3f98ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(EPOCHS):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    y_pred = model(X_train)\n",
    "    loss = binary_cross_entropy_with_logits(y_pred, y_train.view(-1, 1).float())\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "335d6206",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m model(X_test)\n\u001b[0;32m----> 3\u001b[0m fpr, tpr, thresholds \u001b[38;5;241m=\u001b[39m \u001b[43mroc_curve\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetach\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m auc_score \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mround\u001b[39m(auc(fpr, tpr),\u001b[38;5;241m2\u001b[39m)\n",
      "File \u001b[0;32m/work/submit/dhoang/miniconda3/envs/tau_training/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:992\u001b[0m, in \u001b[0;36mroc_curve\u001b[0;34m(y_true, y_score, pos_label, sample_weight, drop_intermediate)\u001b[0m\n\u001b[1;32m    904\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mroc_curve\u001b[39m(\n\u001b[1;32m    905\u001b[0m     y_true, y_score, \u001b[38;5;241m*\u001b[39m, pos_label\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, drop_intermediate\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    906\u001b[0m ):\n\u001b[1;32m    907\u001b[0m     \u001b[38;5;124;03m\"\"\"Compute Receiver operating characteristic (ROC).\u001b[39;00m\n\u001b[1;32m    908\u001b[0m \n\u001b[1;32m    909\u001b[0m \u001b[38;5;124;03m    Note: this implementation is restricted to the binary classification task.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    990\u001b[0m \u001b[38;5;124;03m    array([1.8 , 0.8 , 0.4 , 0.35, 0.1 ])\u001b[39;00m\n\u001b[1;32m    991\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 992\u001b[0m     fps, tps, thresholds \u001b[38;5;241m=\u001b[39m \u001b[43m_binary_clf_curve\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    993\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_score\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpos_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpos_label\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\n\u001b[1;32m    994\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    996\u001b[0m     \u001b[38;5;66;03m# Attempt to drop thresholds corresponding to points in between and\u001b[39;00m\n\u001b[1;32m    997\u001b[0m     \u001b[38;5;66;03m# collinear with other points. These are always suboptimal and do not\u001b[39;00m\n\u001b[1;32m    998\u001b[0m     \u001b[38;5;66;03m# appear on a plotted ROC curve (and thus do not affect the AUC).\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1003\u001b[0m     \u001b[38;5;66;03m# but does not drop more complicated cases like fps = [1, 3, 7],\u001b[39;00m\n\u001b[1;32m   1004\u001b[0m     \u001b[38;5;66;03m# tps = [1, 2, 4]; there is no harm in keeping too many thresholds.\u001b[39;00m\n\u001b[1;32m   1005\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m drop_intermediate \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(fps) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m:\n",
      "File \u001b[0;32m/work/submit/dhoang/miniconda3/envs/tau_training/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:755\u001b[0m, in \u001b[0;36m_binary_clf_curve\u001b[0;34m(y_true, y_score, pos_label, sample_weight)\u001b[0m\n\u001b[1;32m    753\u001b[0m y_score \u001b[38;5;241m=\u001b[39m column_or_1d(y_score)\n\u001b[1;32m    754\u001b[0m assert_all_finite(y_true)\n\u001b[0;32m--> 755\u001b[0m \u001b[43massert_all_finite\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_score\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    757\u001b[0m \u001b[38;5;66;03m# Filter out zero-weighted samples, as they should not impact the result\u001b[39;00m\n\u001b[1;32m    758\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/work/submit/dhoang/miniconda3/envs/tau_training/lib/python3.8/site-packages/sklearn/utils/validation.py:190\u001b[0m, in \u001b[0;36massert_all_finite\u001b[0;34m(X, allow_nan, estimator_name, input_name)\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21massert_all_finite\u001b[39m(\n\u001b[1;32m    165\u001b[0m     X,\n\u001b[1;32m    166\u001b[0m     \u001b[38;5;241m*\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    169\u001b[0m     input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    170\u001b[0m ):\n\u001b[1;32m    171\u001b[0m     \u001b[38;5;124;03m\"\"\"Throw a ValueError if X contains NaN or infinity.\u001b[39;00m\n\u001b[1;32m    172\u001b[0m \n\u001b[1;32m    173\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    188\u001b[0m \u001b[38;5;124;03m        documentation.\u001b[39;00m\n\u001b[1;32m    189\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 190\u001b[0m     \u001b[43m_assert_all_finite\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    191\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43missparse\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    192\u001b[0m \u001b[43m        \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_nan\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    193\u001b[0m \u001b[43m        \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    194\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    195\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/work/submit/dhoang/miniconda3/envs/tau_training/lib/python3.8/site-packages/sklearn/utils/validation.py:161\u001b[0m, in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m estimator_name \u001b[38;5;129;01mand\u001b[39;00m input_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m has_nan_error:\n\u001b[1;32m    145\u001b[0m     \u001b[38;5;66;03m# Improve the error message on how to handle missing values in\u001b[39;00m\n\u001b[1;32m    146\u001b[0m     \u001b[38;5;66;03m# scikit-learn.\u001b[39;00m\n\u001b[1;32m    147\u001b[0m     msg_err \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    148\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not accept missing values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    149\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m encoded as NaN natively. For supervised learning, you might want\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    159\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m#estimators-that-handle-nan-values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    160\u001b[0m     )\n\u001b[0;32m--> 161\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg_err)\n",
      "\u001b[0;31mValueError\u001b[0m: Input contains NaN."
     ]
    }
   ],
   "source": [
    "y_pred = model(X_test)\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred.detach().numpy())\n",
    "\n",
    "auc_score = round(auc(fpr, tpr),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4a66a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create plot for ROC\n",
    "plt.figure(1)\n",
    "\n",
    "plt.plot([0,1],[0,1],'k--')\n",
    "plt.plot(fpr, tpr, label = 'Tau NN, AUC: {}'.format(auc_score))\n",
    "\n",
    "#Establish labels and save image\n",
    "plt.xlabel('False positive rate')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e7bffa5",
   "metadata": {},
   "source": [
    "## Make efficiency plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f773e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the test indices\n",
    "test_index = np.load(\"../ntuples/Jan_17_2023/index_test.npy\")\n",
    "\n",
    "sig = uproot4.open(\"../ntuples/Jan_17_2023/test_sig_v8.root\")\n",
    "tau_pt = sig['ntuplePupSingle']['tree']['pt'].array()[test_index]\n",
    "\n",
    "#Get all the inputs\n",
    "sig_input = sig['ntuplePupSingle']['tree']['m_inputs'].array()[test_index]\n",
    "\n",
    "pt_sig = sig['ntuplePupSingle']['tree']['pt'].array()[test_index]\n",
    "deltaR_sig = sig['ntuplePupSingle']['tree']['gendr1'].array()[test_index]\n",
    "selection_sig = (pt_sig > 20) &(abs(deltaR_sig) < 0.4)\n",
    "\n",
    "#Selected out the tau pt with the basic cuts first\n",
    "tau_pt_cut = tau_pt[selection_sig]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6479816d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sig = torch.from_numpy(np.asarray(sig_input[selection_sig]))\n",
    "y_sig = model(X_sig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01b4434b",
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_cut = y_sig.detach().numpy().flatten() > 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d1afcc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tau_pt_nn = np.asarray(tau_pt_cut)[nn_cut]\n",
    "\n",
    "#Old nn\n",
    "old_tau_select = np.asarray(sig['ntuplePupSingle']['tree']['passLoose'].array()[test_index][selection_sig])\n",
    "tau_pt_old_nn = tau_pt_cut[old_tau_select == 1]\n",
    "\n",
    "#Fill two plots and divide the two.\n",
    "pT_egdes = [0,10,15,20,25,30,35,40,45,50,55,60,70,80,100,125,150] #200?\n",
    "pT_axis = hist.axis.Variable(pT_egdes, name = r\"$\\tau_h$ $p_T$\")\n",
    "\n",
    "hist_all_tau = Hist(pT_axis)\n",
    "hist_selected_tau = Hist(pT_axis)\n",
    "hist_selected_old_tau = Hist(pT_axis)\n",
    "\n",
    "hist_all_tau.fill(tau_pt_cut)\n",
    "hist_selected_tau.fill(tau_pt_nn)\n",
    "hist_selected_old_tau.fill(tau_pt_old_nn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "565472f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 12))\n",
    "main_ax_artists, eff_new_nn_artists = hist_selected_tau.plot_ratio(\n",
    "    hist_all_tau,\n",
    "    rp_num_label=r\"Selected Taus (New NN Score > 0.5)\",\n",
    "    rp_denom_label=r\"All Taus [abs(gendr1) < 0.4, pt > 20GeV]\",\n",
    "    rp_uncert_draw_type=\"bar\",\n",
    "    rp_uncertainty_type=\"efficiency\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d55d286",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 12))\n",
    "main_ax_artists, eff_old_nn_artists = hist_selected_old_tau.plot_ratio(\n",
    "    hist_all_tau,\n",
    "    rp_num_label=r\"Selected Taus (Old NN)\",\n",
    "    rp_denom_label=r\"All Taus [abs(gendr1) < 0.4, pt > 20GeV]\",\n",
    "    rp_uncert_draw_type=\"bar\",\n",
    "    rp_uncertainty_type=\"efficiency\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49f21df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The real efficiency plot\n",
    "fig = plt.figure()\n",
    "\n",
    "eff_new_nn_x = [eff_new_nn_artists.bar.patches[i].get_x() for i in range(len(eff_new_nn_artists.bar.patches))]\n",
    "eff_new_nn_y = [eff_new_nn_artists.bar.patches[i].get_y() for i in range(len(eff_new_nn_artists.bar.patches))]\n",
    "eff_new_nn_err = eff_new_nn_artists.bar.datavalues\n",
    "\n",
    "eff_old_nn_x = [eff_old_nn_artists.bar.patches[i].get_x() for i in range(len(eff_old_nn_artists.bar.patches))]\n",
    "eff_old_nn_y = [eff_old_nn_artists.bar.patches[i].get_y() for i in range(len(eff_old_nn_artists.bar.patches))]\n",
    "eff_old_nn_err = eff_old_nn_artists.bar.datavalues\n",
    "\n",
    "plt.errorbar(eff_new_nn_x, eff_new_nn_y, yerr=eff_new_nn_err, fmt='o', label = 'Retrained Tau NN')\n",
    "plt.errorbar(eff_old_nn_x, eff_old_nn_y, yerr=eff_old_nn_err, fmt='o', label = 'Old Tau NN')\n",
    "\n",
    "plt.hlines(1, 0, 150, linestyles='dashed', color='black', linewidth=3)\n",
    "plt.ylim([0,1.1])\n",
    "plt.xlim([0,150])\n",
    "plt.xlabel(r\"$\\tau_h$ $p_T$\")\n",
    "plt.ylabel(\"Efficiency\")\n",
    "plt.legend(loc = 'center right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4b02e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "tau_eta = sig['ntuplePupSingle']['tree']['eta'].array()[test_index]\n",
    "tau_eta_cut = tau_eta[selection_sig]\n",
    "tau_eta_nn = np.asarray(tau_eta_cut)[nn_cut]\n",
    "\n",
    "#Old nn\n",
    "old_tau_select = np.asarray(sig['ntuplePupSingle']['tree']['passLoose'].array()[test_index][selection_sig])\n",
    "tau_eta_old_nn = tau_eta_cut[old_tau_select == 1]\n",
    "\n",
    "#Fill two plots and divide the two.\n",
    "eta_egdes = [-2.5,-2.3,-2.0,-1.8,-1.6,-1.4,-1.0,-0.6,-0.2,0.2,0.6,1.0,1.4,1.6,1.8,2.0,2.3,2.5]\n",
    "eta_axis = hist.axis.Variable(eta_egdes, name = r\"$\\tau_h$ $\\eta$\")\n",
    "\n",
    "hist_all_tau = Hist(eta_axis)\n",
    "hist_selected_tau = Hist(eta_axis)\n",
    "hist_selected_old_tau = Hist(eta_axis)\n",
    "\n",
    "hist_all_tau.fill(tau_eta_cut)\n",
    "hist_selected_tau.fill(tau_eta_nn)\n",
    "hist_selected_old_tau.fill(tau_eta_old_nn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "842a5e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 12))\n",
    "main_ax_artists, eff_new_nn_artists = hist_selected_tau.plot_ratio(\n",
    "    hist_all_tau,\n",
    "    rp_num_label=r\"Selected Taus (NN Score > 0.5)\",\n",
    "    rp_denom_label=r\"All Taus\",\n",
    "    rp_uncert_draw_type=\"bar\",\n",
    "    rp_uncertainty_type=\"efficiency\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6a2d0a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 12))\n",
    "main_ax_artists, eff_old_nn_artists = hist_selected_old_tau.plot_ratio(\n",
    "    hist_all_tau,\n",
    "    rp_num_label=r\"Selected Taus (NN Score > 0.5)\",\n",
    "    rp_denom_label=r\"All Taus\",\n",
    "    rp_uncert_draw_type=\"bar\",\n",
    "    rp_uncertainty_type=\"efficiency\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5b58b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The real efficiency plot\n",
    "fig = plt.figure()\n",
    "\n",
    "eff_new_nn_x = [eff_new_nn_artists.bar.patches[i].get_x() for i in range(len(eff_new_nn_artists.bar.patches))]\n",
    "eff_new_nn_y = [eff_new_nn_artists.bar.patches[i].get_y() for i in range(len(eff_new_nn_artists.bar.patches))]\n",
    "eff_new_nn_err = eff_new_nn_artists.bar.datavalues\n",
    "\n",
    "eff_old_nn_x = [eff_old_nn_artists.bar.patches[i].get_x() for i in range(len(eff_old_nn_artists.bar.patches))]\n",
    "eff_old_nn_y = [eff_old_nn_artists.bar.patches[i].get_y() for i in range(len(eff_old_nn_artists.bar.patches))]\n",
    "eff_old_nn_err = eff_old_nn_artists.bar.datavalues\n",
    "\n",
    "plt.errorbar(eff_new_nn_x, eff_new_nn_y, yerr=eff_new_nn_err, fmt='o', label = 'Retrained Tau NN')\n",
    "plt.errorbar(eff_old_nn_x, eff_old_nn_y, yerr=eff_old_nn_err, fmt='o', label = 'Old Tau NN')\n",
    "\n",
    "plt.hlines(1, -2.5, 2.5, linestyles='dashed', color='black', linewidth=3)\n",
    "plt.ylim([0,1.1])\n",
    "plt.xlim([-2.5,2.5])\n",
    "plt.xlabel(r\"$\\tau_h$ $\\eta$\")\n",
    "plt.ylabel(\"Efficiency\")\n",
    "plt.legend(loc = 'center right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "089c8e1f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
